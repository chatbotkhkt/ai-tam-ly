import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from load_docs import build_vector_store, load_vector_store
from prompt import SYSTEM_PROMPT

load_dotenv()

st.set_page_config(page_title="AI TÆ° váº¥n tÃ¢m lÃ½", layout="wide")

st.title("ğŸ§  AI TÆ° váº¥n tÃ¢m lÃ½ (Äá»c tÃ i liá»‡u cá»§a báº¡n)")

if "db" not in st.session_state:
    st.session_state.db = None

if "messages" not in st.session_state:
    st.session_state.messages = []

with st.sidebar:
    st.header("ğŸ“„ TÃ i liá»‡u PDF")

    if st.button("ğŸ”„ Táº¡o / Cáº­p nháº­t dá»¯ liá»‡u"):
        with st.spinner("Äang Ä‘á»c PDF vÃ  táº¡o vector..."):
            st.session_state.db = build_vector_store()
        st.success("âœ… ÄÃ£ sáºµn sÃ ng")

# Chat history
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).markdown(msg["content"])

user_input = st.chat_input("Báº¡n Ä‘ang cáº£m tháº¥y tháº¿ nÃ o?")

if user_input:
    st.chat_message("user").markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.spinner("AI Ä‘ang suy nghÄ©..."):
        if st.session_state.db is None:
            db = load_vector_store()
            st.session_state.db = db
        else:
            db = st.session_state.db

        docs = db.similarity_search(user_input, k=4)
        context = "\n\n".join([d.page_content for d in docs])

        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.4)

        prompt = f"""
{SYSTEM_PROMPT}

DÆ°á»›i Ä‘Ã¢y lÃ  ná»™i dung tá»« tÃ i liá»‡u:
{context}

CÃ¢u há»i ngÆ°á»i dÃ¹ng:
{user_input}
"""

        response = llm.invoke(prompt)

    st.chat_message("assistant").markdown(response.content)
    st.session_state.messages.append(
        {"role": "assistant", "content": response.content}
    )
